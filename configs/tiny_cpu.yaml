# Model
vocab_type: char
vocab_size: null        # inferred automatically
context_length: 64

n_layers: 2
n_heads: 4
d_model: 128
d_ff: 512
dropout: 0.1

# Training
batch_size: 8
learning_rate: 0.0003
weight_decay: 0.01
max_steps: 3000
grad_clip: 1.0

# Logging / checkpoints
log_interval: 100
sample_interval: 500
checkpoint_dir: checkpoints

# Device
device: cpu
seed: 42
